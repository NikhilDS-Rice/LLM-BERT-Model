# -*- coding: utf-8 -*-
"""BERT vs LSTM Mcnemar test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xRDVRXmMlyyxV6tmwY770Q69gUe4t5n9
"""

import pandas as pd
import torch
from transformers import BertTokenizer, BertForSequenceClassification
from torch.cuda.amp import autocast

# Load the saved BERT model and tokenizer
MODEL_PATH = "/content/Bert_model"  # Replace with the folder containing your model
tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)
model = BertForSequenceClassification.from_pretrained(MODEL_PATH)

# Ensure the model is in evaluation mode
model.eval()

# Load the dataset
file_path = "/content/youtube_comments_test.csv"  # Replace with your dataset path
df = pd.read_csv(file_path)

# Free up GPU memory before running
torch.cuda.empty_cache()

# Function for batch processing with mixed precision
def get_predictions_in_batches_fp16(texts, model, tokenizer, device='cpu', batch_size=8):
    """Generates predictions using FP16 for reduced memory usage."""
    model.to(device)
    predictions = []

    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i : i + batch_size]
        encodings = tokenizer(
            batch_texts.tolist(),
            truncation=True,
            padding=True,
            max_length=128,
            return_tensors="pt"
        )
        input_ids = encodings['input_ids'].to(device)
        attention_mask = encodings['attention_mask'].to(device)

        with torch.no_grad():
            with autocast():  # Enable mixed precision
                outputs = model(input_ids, attention_mask=attention_mask)
                logits = outputs.logits
                batch_predictions = torch.argmax(logits, dim=-1).cpu().numpy()
                predictions.extend(batch_predictions)

    return predictions

# Set device
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# Preprocess comment_text column and make predictions
texts = df['comment_text'].fillna("")  # Ensure no NaN values
batch_size = 8  # Adjust batch size based on GPU capacity
raw_predictions = get_predictions_in_batches_fp16(texts, model, tokenizer, device, batch_size=batch_size)

# Replace -1 with 2, leave other predictions unchanged
updated_predictions = [2 if pred == 0 else (0 if pred == 1 else 1) for pred in raw_predictions]

# Create a new DataFrame with desired columns
new_file_df = pd.DataFrame({
    'comment_text': df['comment_text'],
    'predictions_BERT': updated_predictions
})

# Save the new DataFrame to a new file
output_path = "predictions_BERT.csv"
new_file_df.to_csv(output_path, index=False)

# Display the first few rows of the new DataFrame
print("Predictions complete. New file created at:", output_path)
print(new_file_df.head())

import pandas as pd

# Function to extract true labels from the CSV
def get_true_labels(csv_file_path):
    """
    Reads a CSV file and returns true labels with -1 replaced by 2.
    :param csv_file_path: Path to the input CSV file.
    :return: List of true labels.
    """
    # Load the CSV file
    data = pd.read_csv(csv_file_path)

    # Check if 'pol' column exists
    if "pol" not in data.columns:
        raise ValueError("The required column 'pol' is missing in the file.")

    # Replace -1 with 2 in the 'pol' column
    data['pol'] = data['pol'].replace(-1, 2)

    #Extract comments
    comment_text = data['comment_text']

    # Extract the true labels as a list
    true_labels = data['pol'].tolist()

    return true_labels, comment_text

# Path to your CSV file
csv_file_path = "youtube_comments_test.csv"

# Get the true labels
true_labels, comment_text = get_true_labels(csv_file_path)

# Create a new DataFrame
new_file_df = pd.DataFrame({
    'comment_text': comment_text,
    'true_labels': true_labels
})

# Save the new DataFrame to a new file
output_path = "true_labels.csv"
new_file_df.to_csv(output_path, index=False)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mlxtend.evaluate import mcnemar

def mcnemar_matrix(true_labels, model1_preds, model2_preds):
    # Contingency table initialization
    contingency_table = np.zeros((2, 2), dtype=int)

    # Populate the contingency table
    for true, pred1, pred2 in zip(true_labels, model1_preds, model2_preds):
        if pred1 == true and pred2 == true:
            contingency_table[0, 0] += 1  # Both correct
        elif pred1 == true and pred2 != true:
            contingency_table[0, 1] += 1  # Model 1 correct, Model 2 wrong
        elif pred1 != true and pred2 == true:
            contingency_table[1, 0] += 1  # Model 2 correct, Model 1 wrong
        else:
            contingency_table[1, 1] += 1  # Both wrong

    # Perform McNemar's test
    chi2, p = mcnemar(contingency_table, exact=True if np.sum(contingency_table) <= 25 else False)
    print(f"Contingency Table:\n{contingency_table}")
    print(f"Chi-squared: {chi2}, P-value: {p}")

    # Visualization
    fig, ax = plt.subplots(figsize=(6, 6))
    row_labels = ["BERT Correct", "BERT Wrong"]
    col_labels = ["LSTM Correct", "LSTM Wrong"]

    ax.set_xticks(np.arange(2) + 0.5)
    ax.set_yticks(np.arange(2) + 0.75)
    ax.set_xticklabels(col_labels, fontsize=12, fontweight='bold')
    ax.set_yticklabels(row_labels, fontsize=12, fontweight='bold', rotation=90)

    # Remove major ticks
    ax.tick_params(left=False, bottom=False, labeltop=True, labelleft=True)
    ax.invert_yaxis()

    # Draw grid
    for i in range(2):
        for j in range(2):
            ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False, edgecolor='black', lw=2))
            ax.text(j + 0.5, i + 0.5, contingency_table[i, j],
                    ha='center', va='center', fontsize=16, fontweight='bold')

    # Adjust aesthetics
    ax.set_xlim(0, 2)
    ax.set_ylim(0, 2)
    plt.title("McNemar Test Contingency Table", fontsize=16, fontweight='bold', pad=20)
    plt.tight_layout()
    plt.show()

# File paths
true_labels_file = "true_labels.csv"  # Replace with the actual path
lstm_preds_file = "predictions_LSTM.csv"
bert_preds_file = "predictions_BERT.csv"

# Load data
true_df = pd.read_csv(true_labels_file)  # Assuming this file has `comment_text` and `true_labels`
lstm_df = pd.read_csv(lstm_preds_file)
bert_df = pd.read_csv(bert_preds_file)

# Merge dataframes
merged_df = pd.merge(true_df, lstm_df, on="comment_text")
merged_df = pd.merge(merged_df, bert_df, on="comment_text")

# Extract necessary columns
true_labels = merged_df['true_labels'].tolist()
predictions_LSTM = merged_df['predictions_LSTM'].tolist()
predictions_BERT = merged_df['predictions_BERT'].tolist()

# Run McNemar's matrix function
mcnemar_matrix(true_labels, predictions_LSTM, predictions_BERT)